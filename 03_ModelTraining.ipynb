{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_ModelTraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1iNmvK9TsKIz3-0nFIf9Qljb07_Q09_Cc",
      "authorship_tag": "ABX9TyOk2qhepAGXXn4At1j8Lmda"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVHd-Qecihxq"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Ctt7bKiVXu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import scipy.stats # For finding skew in the dataset\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWYkaptojJqM"
      },
      "source": [
        "# Additional package Pycaret for help with model selection\n",
        "# Commented out once results are taken into account\n",
        "\n",
        "#!pip install -q pycaret[full]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp6ri8Iiis6c"
      },
      "source": [
        "# Read in Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJjyshs6ivjy",
        "outputId": "0334f519-450b-4ef9-9d7e-ec717d9cf1eb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Unpickle engineered data\n",
        "\n",
        "df_train = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/ames-housing/Data/train_transformed.pkl')\n",
        "df_test = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/ames-housing/Data/test_transformed.pkl')\n",
        "log_target = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/ames-housing/Data/target_transformed.pkl')\n",
        "\n",
        "# Get test IDs\n",
        "\n",
        "test_ids = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/ames-housing/Data/testids.pkl')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr4kspz6tOoc"
      },
      "source": [
        "# Scale data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(df_train)\n",
        "df_train1 = pd.DataFrame(scaler.transform(df_train), index=df_train.index, columns=df_train.columns)\n",
        "df_test1 = pd.DataFrame(scaler.transform(df_test), index=df_test.index, columns=df_test.columns)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM3QzCEqoiin"
      },
      "source": [
        "# Pycaret to identify top performing algorithms\n",
        "\n",
        "This code is commented out because it is time comsuming and verbose. \n",
        "However, Catboost Regression, Bayesian Ridge, Ridge Regression, and Light Gradient Boosting Machine were identified to be the top performing models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfGocEYnlmmB"
      },
      "source": [
        "#from pycaret.regression import setup, compare_models, models"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxZHEuJ4jI2J"
      },
      "source": [
        "#_ = setup(data=pd.concat([df_train1, log_target], axis=1), target='SalePrice')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi8F7cT5w4rG"
      },
      "source": [
        "#compare_models()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ2HSHgv3NKW"
      },
      "source": [
        "# ModelContainer class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijrpUp_C3Mr9"
      },
      "source": [
        "class ModelContainer():\n",
        "  def __init__(self):\n",
        "    self.models = {}\n",
        "    self.mean_mse = {}\n",
        "    self.std_mse = {}\n",
        "    self.best_model = None\n",
        "    self.kfolds = 0\n",
        "\n",
        "  def add_model(self, model):\n",
        "    self.models[model[0]] = model[1]\n",
        "\n",
        "  def get_results(self, X, y, kfolds=5):\n",
        "    for model_name, model in self.models.items():\n",
        "      neg_mse = cross_val_score(model, X, y, cv=kfolds, scoring='neg_mean_squared_error')\n",
        "      self.mean_mse[model_name] = -1.0*np.mean(neg_mse)\n",
        "      self.std_mse[model_name] = np.std(neg_mse)\n",
        "      self.kfolds = kfolds\n",
        "      print(model_name, 'cross-validated.')\n",
        "\n",
        "  def select_best_model(self):\n",
        "    temp = min(self.mean_mse)\n",
        "    self.best_model = self.models[temp]\n",
        "\n",
        "  def best_model_fit(self, X_train, y_train):\n",
        "    self.best_model.fit(X_train, y_train)\n",
        "\n",
        "  def best_model_predict(self, X_test):\n",
        "    print('The best individual model is:\\n', self.best_model)\n",
        "    return np.exp(self.best_model.predict(X_test))\n",
        "\n",
        "  def ensemble_predict(self, X_train, y_train, X_test, weights): \n",
        "    if len(self.models) != len(weights):\n",
        "      print('Number of weights and models should be the same.')\n",
        "    else:\n",
        "      predictions = {}\n",
        "      final_predictions = np.array\n",
        "      for model_name, model in self.models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions[model_name] = np.exp(model.predict(X_test))\n",
        "\n",
        "      return sum(weights[model_name] * predictions.get(model_name) for model_name in weights)\n",
        "      \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "  def print_summary(self):\n",
        "    print('\\nModel Summaries:\\n')\n",
        "    for model_name, model in self.models.items():\n",
        "      print(model_name, ':')\n",
        "      print('Mean MSE over', self.kfolds.n_splits, 'folds:',  self.mean_mse[model_name], '+/-', self.std_mse[model_name],'\\n')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ0WAhfBw5Mp"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtOL-pPRw7Ag",
        "outputId": "ab954aea-d834-4494-d0e7-01bdd2984e62"
      },
      "source": [
        "!pip install -q catboost"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 67.4 MB 29 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w8JY7way8Q3"
      },
      "source": [
        "# Import relevant packages\n",
        "\n",
        "from sklearn.model_selection import KFold, RepeatedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn.linear_model import Ridge, BayesianRidge\n",
        "from mlxtend.regressor import StackingCVRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tRWkVF_xmkd"
      },
      "source": [
        "### Baseline model\n",
        "\n",
        "Pycaret indicated that CatBoost Regressor is the best performing model. We will choose this as the baseline and seek to improve on it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-frivCv0Rup"
      },
      "source": [
        "kf = KFold(n_splits=10)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brv8QmgUojGC",
        "outputId": "64d80520-4903-438d-a098-286d5984564f"
      },
      "source": [
        "baseline_model = ModelContainer()\n",
        "baseline_model.add_model(('Baseline CatBoost', CatBoostRegressor(verbose=0)))\n",
        "\n",
        "baseline_model.get_results(df_train1, log_target, kfolds=kf)\n",
        "\n",
        "baseline_model.print_summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline CatBoost cross-validated.\n",
            "\n",
            "Model Summaries:\n",
            "\n",
            "Baseline CatBoost :\n",
            "Mean MSE over 10 folds: 0.014940510524764045 +/- 0.004725862229804103 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezq9H1ze4DAv"
      },
      "source": [
        "### Hyperparamter tuning\n",
        "\n",
        "Tune hyperparameters for the 4 candidate algorithms using RandomizedSearchCV. \n",
        "\n",
        "Note that exact parameters will change with each run, but any one set of tuned hyperparameters will get very close to the optimal value so it won't be necessary to modify the hyperparameters everytime.\n",
        "\n",
        "First, define a function that will accept a model and a corresponding parameter grid and return the best combination using GridSearch or RandomizedSearch.\n",
        "\n",
        "Then we tune the hyperparameters for each of the algorithms as follows:\n",
        "\n",
        "* Define the parameter grid for the algorithm with a wide range of parameters\n",
        "\n",
        "* This first run will get us close to the optimal values. Then modify the parameter grid to narrow down the range and make it more granular\n",
        "\n",
        "* This should get us close enough to the actual optimal values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e677O-h5-Yy"
      },
      "source": [
        "def tune_hyperparameters(training_data, training_targets, model, param_grid):\n",
        "\n",
        "  random_search = RandomizedSearchCV(\n",
        "      model,\n",
        "      param_distributions=param_grid,\n",
        "      scoring='neg_mean_squared_error',\n",
        "      n_jobs=-1,\n",
        "      n_iter=20,\n",
        "      cv=10)\n",
        "\n",
        "  random_search.fit(np.array(training_data), np.array(training_targets))\n",
        "  print('Best hyperparameters for', model, 'are:')\n",
        "  print(random_search.best_params_)\n",
        "  print('\\n')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_hjTufMBUhT"
      },
      "source": [
        "param_ridge = {'alpha':[150, 175, 200, 225, 250, 275, 300, 325,350]}\n",
        "\n",
        "param_br = {\n",
        "    'alpha_1':np.linspace(100, 1000, 100),\n",
        "    'alpha_2':np.linspace(100, 1000, 100),\n",
        "    'lambda_1':np.linspace(100,1000, 100),\n",
        "    'lambda_2':np.linspace(1,100, 100)\n",
        "}\n",
        "\n",
        "param_lgbm ={\n",
        "    'num_leaves': np.arange(1, 100, 5),\n",
        "    'min_data_in_leaf': np.arange(1,100,1),\n",
        "    'max_depth': np.arange(1,100,1)\n",
        "}\n",
        "\n",
        "param_cbr= {\n",
        "    'depth': np.arange(1,100,10),\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1],\n",
        "    'iterations': np.arange(100,1000,100)\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S9xZ59OBf50",
        "outputId": "2f0901f5-b15f-40ff-f7b6-9dd92d9076e3"
      },
      "source": [
        "tune_hyperparameters(df_train1, log_target, Ridge(), param_ridge)\n",
        "\n",
        "tune_hyperparameters(df_train1, log_target, BayesianRidge(), param_br)\n",
        "\n",
        "# Commented out becasue the results are too verbose.\n",
        "# Tuning was done a few times and the following params were chosen:\n",
        "# num_leaves: 50, max_depth: 10\n",
        "\n",
        "#tune_hyperparameters(df_train1, log_target, LGBMRegressor(), param_lgbm)\n",
        "\n",
        "# Commented out because it is extremely time consuming and verbose\n",
        "# These will be treated as the final hyperparameters:\n",
        "# 'iterations': 6000, 'depth': 5, 'learning_rate': 0.005\n",
        "\n",
        "#tune_hyperparameters(df_train1, log_target, CatBoostRegressor(), param_cbr)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters for Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "      normalize=False, random_state=None, solver='auto', tol=0.001) are:\n",
            "{'alpha': 150}\n",
            "\n",
            "\n",
            "Best hyperparameters for BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
            "              compute_score=False, copy_X=True, fit_intercept=True,\n",
            "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
            "              normalize=False, tol=0.001, verbose=False) are:\n",
            "{'lambda_2': 19.0, 'lambda_1': 527.2727272727273, 'alpha_2': 618.1818181818182, 'alpha_1': 372.72727272727275}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj-H3XMx5Byw"
      },
      "source": [
        "### Retrain tuned models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaaOHVJPzUXM"
      },
      "source": [
        "tuned_models = ModelContainer()\n",
        "\n",
        "tuned_models.add_model(('Ridge Regression', Ridge(alpha=250)))\n",
        "\n",
        "tuned_models.add_model(('Bayesian Ridge', BayesianRidge(alpha_1=850, alpha_2=550, lambda_1=500, lambda_2=5)))\n",
        "\n",
        "tuned_models.add_model(('LGBM', LGBMRegressor(num_leaves=50, max_depth=5)))\n",
        "\n",
        "tuned_models.add_model(('CatBoost Regressor', CatBoostRegressor(iterations=6000, depth=5, learning_rate=0.005, verbose=0)))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WyNgN5PZRrz",
        "outputId": "1a20704b-7e5e-499d-e616-3b964a5ba4d5"
      },
      "source": [
        "tuned_models.models"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bayesian Ridge': BayesianRidge(alpha_1=850, alpha_2=550, alpha_init=None, compute_score=False,\n",
              "               copy_X=True, fit_intercept=True, lambda_1=500, lambda_2=5,\n",
              "               lambda_init=None, n_iter=300, normalize=False, tol=0.001,\n",
              "               verbose=False),\n",
              " 'CatBoost Regressor': <catboost.core.CatBoostRegressor at 0x7f1dbdbc2dd0>,\n",
              " 'LGBM': LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.1, max_depth=5,\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=100, n_jobs=-1, num_leaves=50, objective=None,\n",
              "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
              " 'Ridge Regression': Ridge(alpha=250, copy_X=True, fit_intercept=True, max_iter=None,\n",
              "       normalize=False, random_state=None, solver='auto', tol=0.001)}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY2stBk4JXfA",
        "outputId": "85b9c694-7863-42a2-e7ad-c581c8e51327"
      },
      "source": [
        "tuned_models.get_results(df_train1, log_target, kfolds=kf)\n",
        "\n",
        "tuned_models.select_best_model()\n",
        "tuned_models.best_model_fit(df_train1, log_target)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression cross-validated.\n",
            "Bayesian Ridge cross-validated.\n",
            "LGBM cross-validated.\n",
            "CatBoost Regressor cross-validated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2LcrUGmU3Ai",
        "outputId": "275b7b6a-51fc-4690-ec1e-fc1f771c64ef"
      },
      "source": [
        "tuned_models.print_summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Summaries:\n",
            "\n",
            "Ridge Regression :\n",
            "Mean MSE over 10 folds: 0.019510598329142502 +/- 0.006157353678586185 \n",
            "\n",
            "Bayesian Ridge :\n",
            "Mean MSE over 10 folds: 0.01651722989747783 +/- 0.005963128503879882 \n",
            "\n",
            "LGBM :\n",
            "Mean MSE over 10 folds: 0.01698802403099343 +/- 0.004876987719375172 \n",
            "\n",
            "CatBoost Regressor :\n",
            "Mean MSE over 10 folds: 0.014699055506051873 +/- 0.004862934851674393 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EGn5uis7Iik"
      },
      "source": [
        "### Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grSLCtsBmJdX",
        "outputId": "615a8f33-47a7-4f47-b3ed-4f710148137b"
      },
      "source": [
        "ensemble_weights = {\n",
        "    'CatBoost Regressor': 0.45,\n",
        "    'Bayesian Ridge':     0.35,\n",
        "    'LGBM':               0.15,\n",
        "    'Ridge Regression':   0.05\n",
        "}\n",
        "\n",
        "ensemble_predictions = tuned_models.ensemble_predict(df_train1, log_target, df_test1, ensemble_weights)\n",
        "best_model_predictions = tuned_models.best_model_predict(df_test1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best individual model is:\n",
            " BayesianRidge(alpha_1=850, alpha_2=550, alpha_init=None, compute_score=False,\n",
            "              copy_X=True, fit_intercept=True, lambda_1=500, lambda_2=5,\n",
            "              lambda_init=None, n_iter=300, normalize=False, tol=0.001,\n",
            "              verbose=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VBBnEZ97LzP"
      },
      "source": [
        "# Submissions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2R9Z0Cj1q_1"
      },
      "source": [
        "submission_bestmodel = pd.concat([test_ids, pd.Series(best_model_predictions, name='SalePrice')], axis=1)\n",
        "submission_ensemble = pd.concat([test_ids, pd.Series(ensemble_predictions, name='SalePrice')], axis=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO4bHFWb2cwH"
      },
      "source": [
        "# Score with best individual model\n",
        "# Score on leaderboard: 0.12574 (lower is better)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgBZnUPE4brz"
      },
      "source": [
        "# Score on leaderboard: 0.12140 (lower is better)\n",
        "submission_ensemble.to_csv('/content/drive/MyDrive/Colab Notebooks/ames-housing/Data/Submission.csv', index=False)"
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}